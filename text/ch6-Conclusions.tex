\chapter{\label{ch6-Conclusions} Conclusion}
\minitoc
\section{Future Prospects}

\subsection{Bayesian Neural Networks}

As mentioned in Chapters \ref{ch:2-CNNs} and \ref{ch:4-VERITASRealData}, the classification scores for individual events from CNN-type methods are not necessarily meaningful on their own.

Some work has been performed in the computer science literature on the subject of implementing such 'Bayesian' iterative dropout methods for ConvLSTM architectures \cite{bayesconv},  but this work is extremely prototypical and stable, open source implementations are not available yet.

One potential option that has seen use in certain Zooniverse projects, and would be significantly simpler to implement, is to simply train multiple classifiers and then average the output scores for given events. With greater available GPU power this might become feasible in the near future for CTA.

\subsection{Advanced Model Selection Methods}

It should be noted that the Bayesian Optimisation presented in Chapter \ref{ch:4-VERITASRealData} is a comparatively simple method of model optimisation. In industry, more advanced methods of model selection are becoming available, such as evolutionary algorithms \cite{evodeep} and neural architecture searches \cite{neural}. However, in general such methods where the entire model architecture can be optimised (and not just hyperparameters) are extremely computationally intensive, even more so than the work in Chapter \ref{ch:4-VERITASRealData}, to the point at which end users such as the CTA collaboration cannot reasonably acquire sufficient compute power to perform them. This might change in the coming years.

\subsection{Upgrading Classical Analysis}
One largely unexplored area in terms of prospects for CTA, is taking analysis methods designed for deep learning analyses and applying them to conventional Hillas-based analysis. In particular, Bayesian optimisation (and more generally the field of AutoML, particularly packages such as \textit{auto-sklearn}\cite{autosklearn}) could be used to optimise Hillas parameter cuts and BDT/RF hyperparameters, and recent developments using the RAPIDS \cite{rapids} library mean GPUs can be used to accelerate BDT and RF training, useful given the data scales of CTA.


\subsection{GAN based simulations and domain adaptation}
There is a wide body of computer science literature on using different variants of GAN, such as SimGAN \cite{simgan} and cyclegan \cite{cyclegan}, as a method of handling domain shifts (such as that between simulated and real data). These rely on enforcing cyclic consistency between performance on different datasets. However, my own investigations of applying such methods to CHEC-S data whereby I attempted to evaluate performance on a test dataset that had minor discrepancies (such as zeroed pixels) applied to it were an abject failure (it was better not to use the GANs whatsoever. This might be a future source of potential methods to handle the real data problem, but I personally think that it's unlikely. The difficulty of adapting GANs to different datasets, the complexity of training them, and the difficulty interpreting them, as well as the additional computational cost, make this methods likely unfeasible. Another issue is the lack of a consistent framework to apply such methods in practice. Whilst there have been attempts at creating such a framework (the best of which is \cite{kerasgan}), there are simply too many alternative GAN models to explore every option in every use case. 

Alternatively, GANs can be used as a fast pseudo-simulation method. Whilst this is unlikely to be useful for replacing CORSIKA/sim\_telarray (our attempts at this also failed, due to so called mode-collapse, whereby similar images are repeatedly generated), one potentially useful use of this (proportionately fast) technique would be as a simulator of NSB, as GANs appear reasonably reliable at pseudo-simulation of noise (see for example results on CMB data in \cite{darshgan}). 

\subsection{Graph Networks}
Given the results in Chapter \ref{ch:4-VERITASRealData}, it seems unlikely that CNN-based methods of event classification based on charge data (and not utilising timing information as in Chapter \ref{ch:3-TimingInfo}) will be prohibitively limited by NSB and instrumental noise unless tailcut cleaning is applited.

An alternative to using new timing based methods would be to use alternative deep learning classifiers to CNNs. One such method is graph-based Chebyshev networks, where the image data is treated as a 2D connected graph and not a 2D Euclidean array. One advantage of this is that it could potentially skip the image mapping step needed for CNN-type analyses, though recent results from \cite{adithesis} suggest that these methods are currently computationally prohibitive, being too VRAM hungry and slow to be of practical use. Additionally, there is no current means of performing stereoscopic analysis with such techniques. This might change in upcoming years, with research into graph-based methods being currently extremely active, and GPU advances can follow research trends.

\subsection{FPGA Analysis and Photon Stream Analysis}

FACT have recently presented results showing the potential use of Field Programmable Gate Arrays to enhance the speed of deep learning based event classification at inference time. Whilst novel and interesting, the fact that this innately limits the analysis to monoscopic reconstruction limits the current potential benefits for sensitivity (since model complexity constraints are enforced when performing such analyses on such simple hardware). However, this may be an interesting avenue of investigation for these analyses methods in the long term. The use of such FPGA-based methods for muon tagging is an interesting potential avenue of investigation. This FACT paper also used timing information in a similar way to our CHEC methods to aid in event classification (albeit in a more computationally costly way than use in Chapter \ref{ch:3-TimingInfo}).

CHEC photon stream stuff when it happens
\subsection{Transfer Learning}

\subsection{Larger Arrays}
Much of the work presented in Chapters \ref{ch:3-TimingInfo} and \ref{ch:4-VERITASRealData} was GPU resource limited, meaning that using simulated arrays truly representative of the SST component of CTA were not possible. Extremely recent, very preliminary work by Meiner et al. has shown first CRNN results from an array of 40 SSTs using the CTLearn framework, but this required significant time on the Wilkes-2 GPU cluster at Cambridge to perform. Optimising such networks beyond what has already been performed would be extremely difficult and computationally intensive, but the power of future GPU clusters may make this tractable. This still does not solve the multiple class telescope problem, however.

In the long term, even if CNN-type methods can be demonstrated to offer increased background rejection power for isolated point sources, this could aid in providing sufficient signal to noise to perform spectral analysis, which might be nessecary for the study of short GRBs from the ground.